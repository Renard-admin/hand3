<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <title>Многофункциональное распознавание</title>
    <style>
        body, html { margin: 0; padding: 0; overflow: hidden; background: #1a1a1a; color: white; font-family: Arial, sans-serif; }
        #container { position: relative; width: 100vw; height: 100vh; }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
        #controls { position: absolute; top: 10px; right: 10px; z-index: 10; display: flex; gap: 10px; }
        button { padding: 10px 20px; background: rgba(0,0,0,0.7); border: none; border-radius: 5px; color: white; cursor: pointer; }
        button:hover { background: rgba(0,0,0,0.9); }
        .annotation { position: absolute; background: rgba(0,0,0,0.7); padding: 4px 8px; border-radius: 3px; }
        .danger { border: 2px solid red; }
        .food { border: 2px solid green; }
        .neutral { border: 2px solid yellow; }
    </style>
</head>
<body>
    <div id="container">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="output"></canvas>
        <canvas id="drawLayer"></canvas>
        <div id="controls">
            <button id="fullscreenBtn">Fullscreen</button>
            <button id="flipCameraBtn">Переключить камеру</button>
            <button id="mirrorBtn">Зеркало: Вкл</button>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

    <script>
        const video = document.getElementById('video');
        const outputCanvas = document.getElementById('output');
        const drawCanvas = document.getElementById('drawLayer');
        const fullscreenBtn = document.getElementById('fullscreenBtn');
        const flipCameraBtn = document.getElementById('flipCameraBtn');
        const mirrorBtn = document.getElementById('mirrorBtn');

        let currentStream;
        let hands, cocoModel;
        let isDrawing = false;
        let fistCount = 0;
        let mirrorEnabled = true;
        let cameraMode = 'user';
        const dangerousItems = ['knife', 'scissors', 'gun'];
        const foodItems = ['apple', 'banana', 'pizza', 'sandwich', 'hot dog', 'donut', 'cake'];

        async function setupCamera() {
            const constraints = {
                video: { facingMode: cameraMode, width: 640, height: 480 }
            };

            currentStream = await navigator.mediaDevices.getUserMedia(constraints);
            video.srcObject = currentStream;
        }

        async function initializeModels() {
            // Mediapipe Hands
            hands = new Hands({locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
            hands.setOptions({maxNumHands: 1, modelComplexity: 1});
            hands.onResults(onHandResults);

            // COCO-SSD
            cocoModel = await cocoSsd.load();

            // Face API
            await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights');
            await faceapi.nets.ageGenderNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights');
            await faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights');
        }

        async function processFrame() {
            if (!video.readyState) return requestAnimationFrame(processFrame);

            const ctx = outputCanvas.getContext('2d');
            outputCanvas.width = video.videoWidth;
            outputCanvas.height = video.videoHeight;
            drawCanvas.width = outputCanvas.width;
            drawCanvas.height = outputCanvas.height;

            // Зеркальное отображение
            if (mirrorEnabled) {
                ctx.translate(outputCanvas.width, 0);
                ctx.scale(-1, 1);
            }

            // Отрисовка видео
            ctx.drawImage(video, 0, 0, outputCanvas.width, outputCanvas.height);

            // Обработка лиц
            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                .withAgeAndGender()
                .withFaceExpressions();

            // Обработка объектов
            const objects = await cocoModel.detect(video);

            // Отрисовка результатов
            drawFaces(detections, ctx);
            drawObjects(objects, ctx);

            if (!mirrorEnabled) ctx.setTransform(1, 0, 0, 1, 0, 0);
            requestAnimationFrame(processFrame);
        }

        function drawFaces(detections, ctx) {
            detections.forEach(detection => {
                const box = detection.detection.box;
                const age = Math.round(detection.age);
                const gender = detection.gender;
                const expression = detection.expressions.asSortedArray()[0].expression;

                ctx.strokeStyle = 'yellow';
                ctx.lineWidth = 2;
                ctx.strokeRect(box.x, box.y, box.width, box.height);

                ctx.fillStyle = 'yellow';
                ctx.fillText(`Возраст: ${age}, Пол: ${gender}, Эмоция: ${expression}`, 
                            box.x, box.y - 10);
            });
        }

        function drawObjects(objects, ctx) {
            objects.forEach(prediction => {
                const [x, y, width, height] = prediction.bbox;
                const label = prediction.class;
                
                ctx.strokeStyle = dangerousItems.includes(label) ? 'red' 
                    : foodItems.includes(label) ? 'green' 
                    : 'yellow';
                
                ctx.lineWidth = 2;
                ctx.strokeRect(x, y, width, height);
                ctx.fillStyle = ctx.strokeStyle;
                ctx.fillText(`${dangerousItems.includes(label) ? 'Опасный' : foodItems.includes(label) ? 'Еда' : ''}: ${label} (${Math.round(prediction.score * 100)}%)`, x, y - 10);
            });
        }

        function onHandResults(results) {
            if (!results.multiHandLandmarks.length) return;

            const landmarks = results.multiHandLandmarks[0];
            const ctx = outputCanvas.getContext('2d');

            // Ограничивающий прямоугольник
            let minX = 1, minY = 1, maxX = 0, maxY = 0;
            landmarks.forEach(pt => {
                minX = Math.min(minX, pt.x);
                minY = Math.min(minY, pt.y);
                maxX = Math.max(maxX, pt.x);
                maxY = Math.max(maxY, pt.y);
            });
            
            ctx.strokeStyle = 'lime';
            ctx.lineWidth = 3;
            ctx.strokeRect(
                minX * outputCanvas.width,
                minY * outputCanvas.height,
                (maxX - minX) * outputCanvas.width,
                (maxY - minY) * outputCanvas.height
            );

            // Логика жестов
            const now = Date.now();
            const fist = isFist(landmarks);
            const pointing = isIndexPointing(landmarks);
            const ok = isOkGesture(landmarks);

            if (fist && !lastFistState && (now - lastTimeFist) > 700) {
                fistCount++;
                lastTimeFist = now;
            }

            if (fistCount >= 2 && pointing) {
                isDrawing = true;
                fistCount = 0;
            }

            if (isDrawing) {
                const indexTip = landmarks[8];
                const x = indexTip.x * drawCanvas.width;
                const y = indexTip.y * drawCanvas.height;
                
                const drawCtx = drawCanvas.getContext('2d');
                drawCtx.fillStyle = 'black';
                drawCtx.beginPath();
                drawCtx.arc(x, y, 5, 0, Math.PI * 2);
                drawCtx.fill();
            }

            if (ok) {
                drawCanvas.getContext('2d').clearRect(0, 0, drawCanvas.width, drawCanvas.height);
                isDrawing = false;
                fistCount = 0;
            }

            lastFistState = fist;
        }

        function isFingerExtended(landmarks, pipIdx, tipIdx) {
            const pip = landmarks[pipIdx];
            const tip = landmarks[tipIdx];
            const wrist = landmarks[0];
            const distTip = Math.hypot(tip.x - wrist.x, tip.y - wrist.y);
            const distPip = Math.hypot(pip.x - wrist.x, pip.y - wrist.y);
            return distTip > distPip * 1.3;
        }

        function isFist(landmarks) {
            const fingers = [
                { pip: 6, tip: 8 },  // указательный
                { pip: 10, tip: 12 }, // средний
                { pip: 14, tip: 16 }, // безымянный
                { pip: 18, tip: 20 }  // мизинец
            ];
            const thumbExtended = isFingerExtended(landmarks, 2, 4);
            const otherFolded = fingers.every(f => !isFingerExtended(landmarks, f.pip, f.tip));
            return !thumbExtended && otherFolded;
        }

        function isIndexPointing(landmarks) {
            const indexExtended = isFingerExtended(landmarks, 6, 8);
            const others = [
                { pip: 10, tip: 12 },
                { pip: 14, tip: 16 },
                { pip: 18, tip: 20 }
            ];
            const othersFolded = others.every(f => !isFingerExtended(landmarks, f.pip, f.tip));
            return indexExtended && othersFolded;
        }

        function isOkGesture(landmarks) {
            const thumbTip = landmarks[4];
            const indexTip = landmarks[8];
            const dx = thumbTip.x - indexTip.x;
            const dy = thumbTip.y - indexTip.y;
            return Math.hypot(dx, dy) < 0.05;
        }

        // Инициализация
        (async () => {
            await setupCamera();
            await initializeModels();
            video.play();
            requestAnimationFrame(processFrame);
        })();

        // Обработчики событий
        fullscreenBtn.addEventListener('click', () => document.getElementById('container').requestFullscreen());
        flipCameraBtn.addEventListener('click', async () => {
            cameraMode = cameraMode === 'user' ? 'environment' : 'user';
            await setupCamera();
        });
        mirrorBtn.addEventListener('click', () => {
            mirrorEnabled = !mirrorEnabled;
            mirrorBtn.textContent = `Зеркало: ${mirrorEnabled ? 'Вкл' : 'Выкл'}`;
        });
    </script>
</body>
</html>

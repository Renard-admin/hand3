html
<!DOCTYPE html>
<html>
<head>
    <title>Multi-Feature Webcam App</title>
    <style>
        body { font-family: Arial; margin: 20px; }
        #video { transform: scaleX(-1); }
        canvas { position: absolute; }
        #controls { margin: 20px 0; }
        button { padding: 10px 20px; margin: 5px; }
    </style>
</head>
<body>
    <div id="controls">
        <button onclick="toggleFullscreen()">Fullscreen</button>
        <button onclick="switchCamera()">Switch Camera</button>
    </div>
    <video id="video" autoplay playsinline></video>
    <canvas id="handCanvas"></canvas>
    <canvas id="faceCanvas"></canvas>
    <canvas id="objectCanvas"></canvas>
    <canvas id="drawCanvas"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

    <script>
        let video, handCanvas, faceCanvas, objectCanvas, drawCanvas;
        let hands, cocoModel, currentStream, facingMode = 'user';
        let drawing = false, fistCount = 0, lastFistTime = 0;
        let drawCtx, faceCtx, objectCtx;

        async function setupCamera() {
            video = document.getElementById('video');
            const constraints = { video: { facingMode } };
            currentStream = await navigator.mediaDevices.getUserMedia(constraints);
            video.srcObject = currentStream;
            await new Promise(resolve => video.onloadedmetadata = resolve);
            video.play();
            resizeCanvases();
        }

        async function loadModels() {
            // Mediapipe Hands
            hands = new Hands({ locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}` });
            hands.setOptions({ maxNumHands: 2, modelComplexity: 1 });
            hands.onResults(onHandResults);

            // Face API
            await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
            await faceapi.nets.ageGenderNet.loadFromUri('/models');
            await faceapi.nets.faceExpressionNet.loadFromUri('/models');

            // COCO SSD
            cocoModel = await cocoSsd.load();
        }

        function resizeCanvases() {
            [handCanvas, faceCanvas, objectCanvas, drawCanvas].forEach(canvas => {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            });
            drawCtx = drawCanvas.getContext('2d');
            faceCtx = faceCanvas.getContext('2d');
            objectCtx = objectCanvas.getContext('2d');
        }

        async function processFrame() {
            if (!video.paused) {
                await detectFaces();
                await detectObjects();
                requestAnimationFrame(processFrame);
            }
        }

        async function detectFaces() {
            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                .withAgeAndGender().withFaceExpressions();
            
            faceCtx.clearRect(0, 0, faceCanvas.width, faceCanvas.height);
            detections.forEach(detection => {
                const box = detection.detection.box;
                faceapi.draw.drawDetections(faceCtx, { box }, { lineWidth: 2, color: 'yellow' });
                const text = `${Math.round(detection.age)}y ${detection.gender} ${Object.keys(detection.expressions).reduce((a, b) => detection.expressions[a] > detection.expressions[b] ? a : b)}`;
                faceCtx.fillText(text, box.x, box.y - 10);
            });
        }

        async function detectObjects() {
            const predictions = await cocoModel.detect(video);
            objectCtx.clearRect(0, 0, objectCanvas.width, objectCanvas.height);
            
            predictions.forEach(prediction => {
                const [x, y, width, height] = prediction.bbox;
                let color = 'yellow';
                let label = prediction.class;

                if (['knife', 'gun', 'scissors'].includes(prediction.class)) {
                    color = 'red';
                    label = `Danger: ${prediction.class}`;
                } else if (['apple', 'banana', 'pizza'].includes(prediction.class)) {
                    color = 'green';
                    label = `Food: ${prediction.class}`;
                }

                objectCtx.strokeStyle = color;
                objectCtx.lineWidth = 2;
                objectCtx.strokeRect(x, y, width, height);
                objectCtx.fillStyle = color;
                objectCtx.fillText(label, x, y > 10 ? y - 5 : y + height + 15);
            });
        }

        function onHandResults(results) {
            handCtx.clearRect(0, 0, handCanvas.width, handCanvas.height);
            if (!results.multiHandLandmarks) return;

            results.multiHandLandmarks.forEach((landmarks, idx) => {
                const handedness = results.multiHandedness[idx].label;
                const thumbTip = landmarks[4];
                const indexTip = landmarks[8];
                const wrist = landmarks[0];
                const pinkyMcp = landmarks[17];

                // Draw bounding box
                const xCoords = landmarks.map(p => p.x * handCanvas.width);
                const yCoords = landmarks.map(p => p.y * handCanvas.height);
                const rect = {
                    x: Math.min(...xCoords),
                    y: Math.min(...yCoords),
                    width: Math.max(...xCoords) - Math.min(...xCoords),
                    height: Math.max(...yCoords) - Math.min(...yCoords)
                };
                handCtx.strokeStyle = 'green';
                handCtx.strokeRect(rect.x, rect.y, rect.width, rect.height);

                // Check gestures
                const distance = Math.hypot(indexTip.x - thumbTip.x, indexTip.y - thumbTip.y);
                const fistThreshold = Math.hypot(wrist.x - pinkyMcp.x, wrist.y - pinkyMcp.y) * 0.3;

                if (distance < fistThreshold) {
                    if (Date.now() - lastFistTime < 500) fistCount++;
                    lastFistTime = Date.now();
                }

                if (fistCount >= 2 && distance > fistThreshold * 2) {
                    drawing = true;
                    fistCount = 0;
                }

                if (distance < fistThreshold * 0.5 && !drawing) {
                    drawCtx.clearRect(0, 0, drawCanvas.width, drawCanvas.height);
                }

                if (drawing && handedness === 'Right') {
                    if (prevX) {
                        drawCtx.beginPath();
                        drawCtx.moveTo(prevX, prevY);
                        drawCtx.lineTo(indexTip.x * drawCanvas.width, indexTip.y * drawCanvas.height);
                        drawCtx.stroke();
                    }
                    prevX = indexTip.x * drawCanvas.width;
                    prevY = indexTip.y * drawCanvas.height;
                } else {
                    prevX = null;
                }
            });
        }

        function toggleFullscreen() {
            const elem = document.documentElement;
            if (!document.fullscreenElement) {
                elem.requestFullscreen();
            } else {
                document.exitFullscreen();
            }
        }

        async function switchCamera() {
            facingMode = facingMode === 'user' ? 'environment' : 'user';
            video.srcObject.getTracks().forEach(track => track.stop());
            await setupCamera();
        }

        (async () => {
            [handCanvas, faceCanvas, objectCanvas, drawCanvas] = 
                ['handCanvas', 'faceCanvas', 'objectCanvas', 'drawCanvas'].map(id => document.getElementById(id));
            
            await setupCamera();
            await loadModels();
            hands.send({ image: video });
            processFrame();
        })();
    </script>
</body>
</html>
